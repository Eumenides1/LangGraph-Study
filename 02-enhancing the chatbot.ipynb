{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3396eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/eumenides/miniforge3/lib/python3.9/site-packages (0.1.9)\n",
      "Requirement already satisfied: langsmith in /Users/eumenides/miniforge3/lib/python3.9/site-packages (0.1.93)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.19 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langgraph) (0.2.22)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langsmith) (3.9.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langsmith) (2.31.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langsmith) (2.6.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.2.19->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.2.19->langgraph) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.2.19->langgraph) (8.2.3)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3,>=0.2.19->langgraph) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from pydantic<3,>=1->langsmith) (4.10.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from pydantic<3,>=1->langsmith) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from pydantic<3,>=1->langsmith) (0.6.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langsmith) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langsmith) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langsmith) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.19->langgraph) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-openai in /Users/eumenides/miniforge3/lib/python3.9/site-packages (0.1.17)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-openai) (1.36.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.20 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-openai) (0.2.22)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (0.1.93)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (2.6.4)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (1.33)\n",
      "Requirement already satisfied: tqdm>4 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.62.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: exceptiongroup in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.20->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain-openai) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.20->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.20->langchain-openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.3.5-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: httpx in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from tavily-python) (0.27.0)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from tavily-python) (0.7.0)\n",
      "Requirement already satisfied: requests in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from tavily-python) (2.31.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from tiktoken>=0.5.1->tavily-python) (2023.12.25)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests->tavily-python) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests->tavily-python) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests->tavily-python) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests->tavily-python) (2.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from httpx->tavily-python) (1.0.5)\n",
      "Requirement already satisfied: anyio in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from httpx->tavily-python) (3.7.1)\n",
      "Requirement already satisfied: sniffio in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from httpx->tavily-python) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from anyio->httpx->tavily-python) (1.2.0)\n",
      "Installing collected packages: tavily-python\n",
      "Successfully installed tavily-python-0.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_community in /Users/eumenides/miniforge3/lib/python3.9/site-packages (0.0.29)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.9-py3-none-any.whl (2.3 MB)\n",
      "     |████████████████████████████████| 2.3 MB 231 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.22 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (0.2.22)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (0.1.93)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (2.31.0)\n",
      "Collecting langchain<0.3.0,>=0.2.9\n",
      "  Downloading langchain-0.2.10-py3-none-any.whl (990 kB)\n",
      "     |████████████████████████████████| 990 kB 79 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (1.23.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain_community) (2.0.28)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.22->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.22->langchain_community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.15)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.10.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.22->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.16.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/eumenides/miniforge3/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Installing collected packages: langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.1\n",
      "    Uninstalling langchain-text-splitters-0.0.1:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.13\n",
      "    Uninstalling langchain-0.1.13:\n",
      "      Successfully uninstalled langchain-0.1.13\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.29\n",
      "    Uninstalling langchain-community-0.0.29:\n",
      "      Successfully uninstalled langchain-community-0.0.29\n",
      "Successfully installed langchain-0.2.10 langchain-community-0.2.9 langchain-text-splitters-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# capture --no-stderr\n",
    "%pip install -U langgraph langsmith\n",
    "\n",
    "# Used for this tutorial; not a requirement for LangGraph\n",
    "%pip install -U langchain-openai\n",
    "%pip install -U tavily-python\n",
    "%pip install -U langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae10b1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: ········\n",
      "API_BASE_URL: ········\n",
      "TAVILY_API_KEY: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"API_BASE_URL\")\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdafbd52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.weather.com.cn/weather/101110101.shtml',\n",
       "  'content': '涂擦SPF大于15、PA+防晒护肤品。\\n无明显降温，感冒机率较低。\\n气温较低，在户外运动请注意增减衣物。\\n无需担心过敏，可放心外出，享受生活。\\n建议着厚外套加毛衣等服装。\\n无雨且风力较小，易保持清洁度。\\n辐射较弱，涂擦SPF12-15、PA+护肤品。\\n大幅度降温，适当增加衣服。\\n有降水，推荐您在室内进行休闲运动。\\n无需担心过敏，可放心外出，享受生活。\\n建议着棉衣加羊毛衫等冬季服装。\\n有雨，雨水和泥水会弄脏爱车。\\n辐射弱，涂擦SPF8-12防晒护肤品。\\n天气资讯\\n周边地区\\n|\\n周边景点\\n2024-01-09 11:30更新\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n周边地区\\n|\\n周边景点\\n2024-01-09 11:30更新\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n高清图集\\n重大天气事件\\n1月9日\\n冷空气难改偏暖格局 南方仍有阴雨来扰\\n本周将有三股冷空气轮番登场，多地气温仍有波动，不过冷空气实力较弱且影响区域偏北，难改气温回升的大趋势。\\n1月8日\\n本周冷空气活跃 南方仍将多阴雨天气\\n今明两天，我国降水主要出现在江南、华南以及贵州、新疆北部等地。此外，本周影响我国的冷空气仍频繁。\\n1月7日\\n冷空气活跃中东部多地气温频繁波动 南方多阴雨天气来扰\\n今天（1月7日）至下周初，我国冷空气活动仍频繁，东北、长江中下游等地气温频繁升降，公众需留意气温变化，及时调整穿着，远离感冒风险。\\n1月6日\\n东北气温起伏明显 南方多地雨水频繁打卡\\n今天（1月6日），受新一股冷空气影响，黄淮南部、江淮北部等地的霾天气逐渐减弱消散。同时，受其影响，东北地区将出现明显降温，后天起又将开启升温。\\n1月5日\\n华北江淮等地今天仍有雾和霾 东北多地迎明显降温\\n今天（1月5日)，华北、黄淮、江淮等地扩散条件仍较差，或现轻至中度霾，明天起冷空气上线，霾天气将逐渐消散。东北多地受冷空气影响还将出现明显降温。\\n1月4日\\n冷空气实力较弱全国大部气温偏高 东北内蒙古迎降雪\\n尽管气温起起伏伏，但总体来看，未来一周全国大部气温仍然以偏暖为主。降水方面，今天内蒙古东部、黑龙江等地将迎降雪，明天江南、华南等降雨有所发展。\\n1月3日\\n中东部气温步入升温通道 南方降雨减少东北等地降雪增多\\n今明中东部大部气温将陆续回升，而6日起，又将有一股冷空气影响我国。降水方面，今明天南方降雨减少，东北等地降雪又将发展增多。\\n1月2日\\n本周中东部气温多起伏 贵州广西等地进入频繁阴雨模式\\n昨天（1月1日），从东北地区到江南，我国多地气温都出现了不同程度下降，明后两天各地气温又会波动回升，这也为进入小寒节气后的又一轮降温埋下伏笔。\\n1月1日\\n“跨年”冷空气继续影响中东部 南方阴雨一波接一波\\n今天（2024年1月1日），冷空气继续影响我国中东部。受冷空气影响，黄淮、江淮等地的大气扩散条件转好。南方降雨逐渐增多，将波及长江以南大部地区，公众出行需注意防雨。\\n12月31日\\n元旦假期后两日南方降雨增多 冷空气持续影响中东部\\n今明两天，新疆北部降雪依然频繁，南方降雨也将逐渐增多。同时，中东部部分地区还将出现4~6℃降温，并伴有大风天气。\\n12月30日\\n元旦假期首日华北黄淮仍有雾和霾天气 新一股冷空气将影响中东部\\n12月30日），华北黄淮仍有大范围雾和霾天气，天津、河北、山东及河南部分地区有重度霾。预计今天傍晚前后，上述地区雾和霾将逐渐消散，能见度转好。\\n12月29日\\n华北黄淮雾和霾天气持续 新疆东北等地降雪发展\\n今明两天（12月29日至30日），华北、黄淮等地大气扩散条件仍较差。预计30日傍晚前后，随着新一股冷空气展开影响，上述地区能见度将逐渐转好。\\n12月28日\\n华北黄淮等地迎今冬以来最强雾和霾过程 中东部雨雪短暂增多\\n今天（12月28日）开始，华北、黄淮等地将迎来今冬最强雾和霾天气过程，其中影响最重时段为明天夜间至30日上午，需注意防范。\\n联播天气预报\\n更多>>高清图集\\n天气视频\\n本周冷空气活跃但势力偏弱\\n天气早安：三九到来 气温多波动\\n>> 生活旅游\\n景点推荐\\n气象产品\\n气象服务\\n天气预报电话查询\\n拨打12121或96121进行天气预报查询\\n手机查询\\n随时随地通过手机登录中国天气WAP版查看各地天气资讯\\n网站服务\\n关于我们联系我们帮助人员招聘\\n客服中心版权声明律师网站地图\\n营销中心\\n商务合作广告服务媒资合作\\n相关链接\\n中国气象局中国气象服务协会 中国天气频道\\n客服邮箱：service@weather.com.cn广告服务：010-58991840媒资合作：010-58993745科普合作：010-58991541京ICP证010385-2号\\u3000京公网安备11041400134号\\n商务合作：010-58991806010-58991938 台风路径\\n空间天气\\n图片\\n专题\\n环境\\n旅游\\n碳中和\\n气象科普\\n一带一路\\n产创平台\\n热门城市\\n热门景点\\n选择省市\\n<<返回\\n全国\\n周边城市\\n周边景点\\n本地乡镇\\n热门城市\\n选择洲际\\n9日（今天）\\n晴转多云\\n14/-1℃\\n<3级\\n10日（明天）\\n阴转晴\\n7/-1℃\\n<3级\\n11日（后天）\\n晴\\n15/-1℃\\n<3级\\n12日（周五）\\n晴转多云\\n15/1℃\\n<3级\\n13日（周六）\\n晴\\n12/0℃\\n<3级\\n14日（周日）\\n多云\\n9/0℃\\n<3级\\n15日（周一）\\n小雨转阴\\n5/0℃\\n<3级\\n蓝天预报综合天气现象、能见度、空气质量等因子，预测未来一周的天空状况。\\n温差较大，较易感冒，注意防护。\\n气温较低，在户外运动请注意增减衣物。\\n无需担心过敏，可放心外出，享受生活。\\n建议着厚外套加毛衣等服装。\\n天气较好，适合擦洗汽车。\\n 涂擦SPF大于15、PA+防晒护肤品。\\n大幅度降温，适当增加衣服。\\n天气寒冷，推荐您进行室内运动。\\n无需担心过敏，可放心外出，享受生活。\\n建议着棉衣加羊毛衫等冬季服装。\\n天气较好，适合擦洗汽车。\\n辐射弱，涂擦SPF8-12防晒护肤品。\\n温差较大，较易感冒，注意防护。\\n天气凉，在户外运动请注意增减衣物。\\n无需担心过敏，可放心外出，享受生活。\\n建议着厚外套加毛衣等服装。\\n天气较好，适合擦洗汽车。\\n 涂擦SPF大于15、PA+防晒护肤品。\\n无明显降温，感冒机率较低。\\n气温较低，在户外运动请注意增减衣物。\\n无需担心过敏，可放心外出，享受生活。\\n建议着厚外套加毛衣等服装。\\n天气较好，适合擦洗汽车。\\n 涂擦SPF大于15、PA+防晒护肤品。\\n天凉，湿度大，较易感冒。\\n天气凉，在户外运动请注意增减衣物。\\n无需担心过敏，可放心外出，享受生活。\\n建议着厚外套加毛衣等服装。\\n天气较好，适合擦洗汽车。\\n'},\n",
       " {'url': 'http://www.nmc.cn/publish/forecast/ASN/xian.html',\n",
       "  'content': '西安天气预报 ; 省份： 城市： ... 本站所刊登的信息、数据和各种专栏材料，未经授权禁止下载使用 . 制作维护：国家气象中心预报系统开放实验室 地址：北京市中关村南大街46号 邮编：100081 . 京公网安备 11040102700100 ...'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"今天西安的天气如何？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb87e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "base_url = os.environ.get(\"API_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",openai_api_key=api_key, openai_api_base=base_url)\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bcd3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7edf939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14380ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 今天宝鸡天气如何？\n",
      "Assistant: \n",
      "Assistant: \"HTTPError('400 Client Error: Bad Request for url: https://api.tavily.com/search')\"\n",
      "Assistant: \n",
      "Assistant: [{\"url\": \"http://www.weather.com.cn/weather/101110901.shtml\", \"content\": \"\\u5b9d\\u9e21\\u5929\\u6c14\\u9884\\u62a5\\uff0c\\u53ca\\u65f6\\u51c6\\u786e\\u53d1\\u5e03\\u4e2d\\u592e\\u6c14\\u8c61\\u53f0\\u5929\\u6c14\\u4fe1\\u606f\\uff0c\\u4fbf\\u6377\\u67e5\\u8be2\\u5b9d\\u9e21\\u4eca\\u65e5\\u5929\\u6c14\\uff0c\\u5b9d\\u9e21\\u5468\\u672b\\u5929\\u6c14\\uff0c\\u5b9d\\u9e21\\u4e00\\u5468\\u5929\\u6c14\\u9884\\u62a5\\uff0c\\u5b9d\\u9e21\\u84dd\\u5929\\u9884\\u62a5\\uff0c\\u5b9d\\u9e21\\u5929\\u6c14\\u9884\\u62a5\\uff0c\\u5b9d\\u9e2140\\u65e5\\u5929\\u6c14\\u9884\\u62a5\\uff0c\\u8fd8\\u63d0\\u4f9b\\u5b9d\\u9e21\\u7684\\u751f\\u6d3b\\u6307\\u6570\\u3001\\u5065\\u5eb7\\u6307\\u6570\\u3001\\u4ea4\\u901a\\u6307\\u6570\\u3001\\u65c5\\u6e38\\u6307\\u6570\\uff0c\\u53ca\\u65f6\\u53d1\\u5e03\\u5b9d\\u9e21\\u6c14\\u8c61\\u9884\\u8b66\\u4fe1\\u53f7\\u3001\\u5404\\u7c7b\\u6c14\\u8c61\\u8d44\\u8baf\\u3002\"}, {\"url\": \"http://www.nmc.cn/publish/forecast/ASN/baoji.html\", \"content\": \"\\u5168\\u7403\\u5929\\u6c14\\u516c\\u62a5; \\u5168\\u7403\\u70ed\\u5e26\\u6c14\\u65cb\\u76d1\\u6d4b\\u516c\\u62a5; wmo\\u7b2cxi\\u6d77\\u533a\\u6d77\\u4e8b\\u5929\\u6c14\\u516c\\u62a5; \\u56fd\\u5916\\u519c\\u4e1a\\u6c14\\u8c61\\u76d1\\u6d4b\\u4e0e\\u4f5c\\u7269\\u5c55\\u671b; \\u5168\\u7403\\u707e\\u5bb3\\u6027\\u5929\\u6c14\\u76d1\\u6d4b\\u6708\\u62a5; \\u5168\\u7403\\u96e8\\u96ea\\u843d\\u533a\\u9884\\u62a5; \\u4e16\\u754c\\u6c14\\u8c61\\u4e2d\\u5fc3\\uff08\\u5317\\u4eac\\uff09\\u95e8\\u6237\\u7f51; \\u4e00\\u5e26\\u4e00\\u8def\\u6c14\\u8c61\\u670d\\u52a1; \\u4e9a\\u6d32\\u6c99\\u5c18\\u66b4\\u9884\\u62a5\\u4e13\\u4e1a\\u6c14\\u8c61\\u4e2d\\u5fc3\"}]\n",
      "Assistant: 今天宝鸡的天气预报可以在以下链接查看：\n",
      "\n",
      "1. [中国天气网 - 宝鸡天气](http://www.weather.com.cn/weather/101110901.shtml)\n",
      "2. [国家气象局 - 宝鸡天气预报](http://www.nmc.cn/publish/forecast/ASN/baoji.html)\n",
      "\n",
      "您可以通过这些链接获取更详细的天气信息。\n",
      "User: 你知道庆余年是本什么书吗？\n",
      "Assistant: 《庆余年》是中国作家猫腻创作的一部网络小说，属于历史穿越类作品。小说讲述了主角范闲穿越到一个架空的历史时代，经历了政治斗争、权谋博弈以及个人情感的故事。该书以其丰富的情节、深刻的角色刻画和幽默的语言风格受到了读者的广泛欢迎。小说还被改编为电视剧，进一步提升了其知名度。\n",
      "User: 中国 90 后退休年龄提高到多少岁了？\n",
      "Assistant: \n",
      "Assistant: [{\"url\": \"https://m.thepaper.cn/newsDetail_forward_11680076\", \"content\": \"\\u4eba\\u793e\\u90e8\\u526f\\u90e8\\u957f\\u4ecb\\u7ecd\\u9053\\uff0c\\u6211\\u56fd\\u4eba\\u5747\\u9884\\u671f\\u5bff\\u547d\\u5df2\\u4ece\\u65b0\\u4e2d\\u56fd\\u6210\\u7acb\\u521d\\u671f\\u768440\\u5c81\\u5de6\\u53f3\\u63d0\\u9ad8\\u5230\\u4e862019\\u5e74\\u768477.3\\u5c81\\uff0c\\u57ce\\u9547\\u5c45\\u6c11\\u4eba\\u5747\\u5bff\\u547d\\u8d85\\u8fc780\\u5c81\\uff0c\\u4f46\\u662f\\u65b0\\u4e2d\\u56fd\\u6210\\u7acb\\u521d\\u671f\\u786e\\u5b9a\\u7684\\u7537\\u602760\\u5c81\\u3001\\u5973\\u5e72\\u90e855\\u5c81\\u3001\\u5973\\u804c\\u5de550\\u5c81\\u7684\\u6cd5\\u5b9a\\u9000\\u4f11\\u5e74\\u9f84\\uff0c\\u8fd170\\u5e74\\u672a\\u6709\\u8c03\\u6574\\uff0c\\u8fd9\\u9020\\u6210\\u4e86\\u4eba\\u529b\\u8d44\\u6e90\\u7684\\u6d6a\\u8d39\\u3002 ... \\u4f5c\\u4e3a90\\u540e ...\"}, {\"url\": \"https://m.thepaper.cn/newsDetail_forward_12082493\", \"content\": \"\\u5b9a\\u4e86!. \\u5ef6\\u8fdf\\u9000\\u4f11!. 70\\u300180\\u300190\\u540e\\u9000\\u4f11\\u5e74\\u9f84\\u5bf9\\u7167\\u8868\\u51fa\\u7089!. \\u300c \\u5ef6\\u8fdf\\u9000\\u4f11 \\u300d. \\u51e0\\u4e4e\\u5173\\u7cfb\\u5230\\u6bcf\\u4e00\\u4e2a\\u4eba\\u7684\\u5207\\u8eab\\u5229\\u76ca. \\u662f\\u8fd1\\u4e9b\\u5e74\\u6765\\u793e\\u4f1a\\u5404\\u754c. \\u4e00\\u76f4\\u90fd\\u9ad8\\u5ea6\\u5173\\u6ce8\\u7684\\u4e00\\u4e2a\\u8bdd\\u9898!. \\u5ef6\\u8fdf\\u9000\\u4f11\\u8fce\\u6765\\u4e86\\u6700\\u65b0\\u6d88\\u606f!. 3\\u670813\\u65e5\\uff0c\\u65b0\\u534e\\u793e\\u53d1\\u5e03\\u300a\\u4e2d\\u534e\\u4eba\\u6c11\\u5171\\u548c\\u56fd\\u56fd\\u6c11\\u7ecf\\u6d4e\\u548c\\u793e\\u4f1a\\u53d1\\u5c55\\u7b2c\\u5341\\u56db\\u4e2a\\u4e94\\u5e74 ...\"}]\n",
      "Assistant: 根据最新消息，中国的退休年龄正在逐步提高。对于90后，男性的退休年龄预计为60岁，女性则为55岁，而女性的某些职业可能会延迟到50岁。目前并没有明确的调整方案，但整体目标是逐步延长退休年龄。\n",
      "\n",
      "如果你想了解更多详细信息，可以查看以下链接：\n",
      "- [新中国成立初期的退休年龄](https://m.thepaper.cn/newsDetail_forward_11680076)\n",
      "- [关于退休年龄的最新讨论](https://m.thepaper.cn/newsDetail_forward_12082493)\n",
      "User: q\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205cb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "base_url = os.environ.get(\"API_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",openai_api_key=api_key, openai_api_base=base_url)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3277cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "Assistant: Hello! How can I assist you today?\n",
      "User: 今天Yum公司美股收盘价是多少\n",
      "Assistant: \n",
      "Assistant: [{'url': 'https://finance.yahoo.com/quote/YUM/history/', 'content': 'Discover historical prices for YUM stock on Yahoo Finance. View daily, weekly or monthly format back to when Yum! ... Close price adjusted for splits. ... Oct 18, 2023: 119.47: 121.56: 119.35: 120 ...'}, {'url': 'https://www.nasdaq.com/market-activity/stocks/yum/historical', 'content': 'Back to YUM Overview. Get up to 10 years of daily historical stock prices & volumes. The \"Close/Last\" is the \"adjust consolidated close price\". Data provided by Edgar Online . The net and ...'}]\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Missing required parameter: 'messages[2].content[0].type'. (request id: 2024072214453645900806194353942)\", 'type': 'invalid_request_error', 'param': 'messages[2].content[0].type', 'code': 'missing_required_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, user_input)]}):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], BaseMessage):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1111\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m-> 1111\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1758\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step, timeout_exc_cls)\u001b[0m\n\u001b[1;32m   1756\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1757\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1761\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1763\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langgraph/pregel/executor.py:43\u001b[0m, in \u001b[0;36mBackgroundExecutor.<locals>.done\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/concurrent/futures/_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/concurrent/futures/thread.py:52\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langgraph/pregel/retry.py:25\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     23\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/runnables/base.py:2871\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2867\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2868\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2869\u001b[0m )\n\u001b[1;32m   2870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2871\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langgraph/utils.py:102\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m    101\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 102\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mchatbot\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchatbot\u001b[39m(state: State):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/runnables/base.py:5055\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5050\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5051\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5052\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5053\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5054\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5056\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5057\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5058\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5059\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:265\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    262\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    264\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 265\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    275\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:698\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    692\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    696\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    697\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:555\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    554\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 555\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    556\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    557\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    559\u001b[0m ]\n\u001b[1;32m    560\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:545\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    544\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 545\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m         )\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:770\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 770\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    774\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:589\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/openai/_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1054\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Missing required parameter: 'messages[2].content[0].type'. (request id: 2024072214453645900806194353942)\", 'type': 'invalid_request_error', 'param': 'messages[2].content[0].type', 'code': 'missing_required_parameter'}}"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f1052f",
   "metadata": {},
   "source": [
    "# 给 chatBot 赋予记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5fa0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6274015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "base_url = os.environ.get(\"API_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",openai_api_key=api_key, openai_api_base=base_url)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c458bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24e21fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "看这里，你好我是小刘同学.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你好，小刘同学！有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "user_input = \"看这里，你好我是小刘同学.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "901219e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "你还记得我叫什么吗?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "当然记得，你叫小刘同学！有什么想和我聊的呢？\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_input = \"你还记得我叫什么吗?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1230f856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "你还记得我叫什么吗?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "抱歉，我无法记住或存储个人信息，包括你的名字。如果你告诉我你的名字，我可以在这个对话中使用它。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce4e9ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='看这里，你好我是小刘同学.', id='8d8fbd41-1ed5-4780-938b-f494770e4b2a'), AIMessage(content='你好，小刘同学！有什么我可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 89, 'total_tokens': 103}, 'model_name': 'openai/gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-36a137aa-d3d7-4613-9ac0-e8b5de5ba37e-0', usage_metadata={'input_tokens': 89, 'output_tokens': 14, 'total_tokens': 103}), HumanMessage(content='你还记得我叫什么吗?', id='f98b95f7-0696-41bf-9160-07094de89ef2'), AIMessage(content='当然记得，你叫小刘同学！有什么想和我聊的呢？', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 118, 'total_tokens': 137}, 'model_name': 'openai/gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-b4bdff38-fab2-46e8-b37f-b4a587cec665-0', usage_metadata={'input_tokens': 118, 'output_tokens': 19, 'total_tokens': 137})]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef483b2-aff9-6a62-8004-06c910497a3f'}}, metadata={'source': 'loop', 'step': 4, 'writes': {'chatbot': {'messages': [AIMessage(content='当然记得，你叫小刘同学！有什么想和我聊的呢？', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 118, 'total_tokens': 137}, 'model_name': 'openai/gpt-4o-mini', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-b4bdff38-fab2-46e8-b37f-b4a587cec665-0', usage_metadata={'input_tokens': 118, 'output_tokens': 19, 'total_tokens': 137})]}}}, created_at='2024-07-22T15:00:43.343895+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef483b2-9c28-695c-8003-10a682bf7ac7'}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad51ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
